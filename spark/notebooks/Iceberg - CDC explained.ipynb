{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1041ae6f",
   "metadata": {},
   "source": [
    "![iceberg-logo](https://www.apache.org/logos/res/iceberg/iceberg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb2ab",
   "metadata": {},
   "source": [
    "### [Docker, Spark, and Iceberg: The Fastest Way to Try Iceberg!](https://tabular.io/blog/docker-spark-and-iceberg/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5c8206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 11:44:27 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://981a1bf21baf:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff61b83940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f41",
   "metadata": {},
   "source": [
    "## Load One Month of NYC Taxi/Limousine Trip Data\n",
    "\n",
    "For this notebook, we will use the New York City Taxi and Limousine Commision Trip Record Data that's available on the AWS Open Data Registry. This contains data of trips taken by taxis and for-hire vehicles in New York City. We'll save this into an iceberg table called `taxis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bee98",
   "metadata": {},
   "source": [
    "To be able to rerun the notebook several times, let's drop the table if it exists to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930682ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f918310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c37ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2021-04.parquet\")\n",
    "df.write.saveAsTable(\"nyc.taxis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fddb808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>col_name</th>\n",
       "            <th>data_type</th>\n",
       "            <th>comment</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>VendorID</td>\n",
       "            <td>bigint</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>tpep_pickup_datetime</td>\n",
       "            <td>timestamp_ntz</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>tpep_dropoff_datetime</td>\n",
       "            <td>timestamp_ntz</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>passenger_count</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>trip_distance</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>RatecodeID</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>store_and_fwd_flag</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>PULocationID</td>\n",
       "            <td>bigint</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>DOLocationID</td>\n",
       "            <td>bigint</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>payment_type</td>\n",
       "            <td>bigint</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>fare_amount</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>extra</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>mta_tax</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>tip_amount</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>tolls_amount</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>improvement_surcharge</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>total_amount</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>congestion_surcharge</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>airport_fee</td>\n",
       "            <td>double</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Metadata Columns</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_spec_id</td>\n",
       "            <td>int</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_partition</td>\n",
       "            <td>struct&lt;&gt;</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_file</td>\n",
       "            <td>string</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_pos</td>\n",
       "            <td>bigint</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_deleted</td>\n",
       "            <td>boolean</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Detailed Table Information</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Name</td>\n",
       "            <td>demo.nyc.taxis</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Type</td>\n",
       "            <td>MANAGED</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Location</td>\n",
       "            <td>s3://warehouse/nyc/taxis</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Provider</td>\n",
       "            <td>iceberg</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Owner</td>\n",
       "            <td>root</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Table Properties</td>\n",
       "            <td>[created-at=2024-06-29T11:44:59.713327429Z,current-snapshot-id=5966246261817241078,format=iceberg/parquet,format-version=2,write.format.default=parquet,write.parquet.compression-codec=zstd]</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                     col_name |                                                                                                                                                                                     data_type | comment |\n",
       "+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                     VendorID |                                                                                                                                                                                        bigint |    None |\n",
       "|         tpep_pickup_datetime |                                                                                                                                                                                 timestamp_ntz |    None |\n",
       "|        tpep_dropoff_datetime |                                                                                                                                                                                 timestamp_ntz |    None |\n",
       "|              passenger_count |                                                                                                                                                                                        double |    None |\n",
       "|                trip_distance |                                                                                                                                                                                        double |    None |\n",
       "|                   RatecodeID |                                                                                                                                                                                        double |    None |\n",
       "|           store_and_fwd_flag |                                                                                                                                                                                        string |    None |\n",
       "|                 PULocationID |                                                                                                                                                                                        bigint |    None |\n",
       "|                 DOLocationID |                                                                                                                                                                                        bigint |    None |\n",
       "|                 payment_type |                                                                                                                                                                                        bigint |    None |\n",
       "|                  fare_amount |                                                                                                                                                                                        double |    None |\n",
       "|                        extra |                                                                                                                                                                                        double |    None |\n",
       "|                      mta_tax |                                                                                                                                                                                        double |    None |\n",
       "|                   tip_amount |                                                                                                                                                                                        double |    None |\n",
       "|                 tolls_amount |                                                                                                                                                                                        double |    None |\n",
       "|        improvement_surcharge |                                                                                                                                                                                        double |    None |\n",
       "|                 total_amount |                                                                                                                                                                                        double |    None |\n",
       "|         congestion_surcharge |                                                                                                                                                                                        double |    None |\n",
       "|                  airport_fee |                                                                                                                                                                                        double |    None |\n",
       "|                              |                                                                                                                                                                                               |         |\n",
       "|           # Metadata Columns |                                                                                                                                                                                               |         |\n",
       "|                     _spec_id |                                                                                                                                                                                           int |         |\n",
       "|                   _partition |                                                                                                                                                                                      struct<> |         |\n",
       "|                        _file |                                                                                                                                                                                        string |         |\n",
       "|                         _pos |                                                                                                                                                                                        bigint |         |\n",
       "|                     _deleted |                                                                                                                                                                                       boolean |         |\n",
       "|                              |                                                                                                                                                                                               |         |\n",
       "| # Detailed Table Information |                                                                                                                                                                                               |         |\n",
       "|                         Name |                                                                                                                                                                                demo.nyc.taxis |         |\n",
       "|                         Type |                                                                                                                                                                                       MANAGED |         |\n",
       "|                     Location |                                                                                                                                                                      s3://warehouse/nyc/taxis |         |\n",
       "|                     Provider |                                                                                                                                                                                       iceberg |         |\n",
       "|                        Owner |                                                                                                                                                                                          root |         |\n",
       "|             Table Properties | [created-at=2024-06-29T11:44:59.713327429Z,current-snapshot-id=5966246261817241078,format=iceberg/parquet,format-version=2,write.format.default=parquet,write.parquet.compression-codec=zstd] |         |\n",
       "+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DESCRIBE EXTENDED nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf99fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2171187</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------+\n",
       "|     cnt |\n",
       "+---------+\n",
       "| 2171187 |\n",
       "+---------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd8475d-9378-47e6-9f39-70413ff22549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.9/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-26.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9915ba-f481-4039-933e-a9dfd3738008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, expr\n",
    "from datetime import datetime as dt\n",
    "from faker import Faker\n",
    "from uuid import uuid1\n",
    "\n",
    "fake = Faker()\n",
    "GLOBAL_TEST_PATH = 'tests/test_data'\n",
    "DATA_PATHS = {\n",
    "    'DMS': {\n",
    "        'SOURCE': f'{GLOBAL_TEST_PATH}/db_data',\n",
    "        'SINK': f'{GLOBAL_TEST_PATH}/dms_sink'\n",
    "    }\n",
    "}\n",
    "TABLES = {\n",
    "    1: {\n",
    "        'name': 'demo',\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "009e9b07-14a0-436e-85c9-6c53b94fd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_dimension_table_dataframe(spark, row_count=10):\n",
    "    \"\"\" Create initial test data for dimension table\n",
    "    This function creates both pre- and post- transformation data\n",
    "    saved as Parquet files in tests/test_data. This will be used for\n",
    "    unit tests as well as to load as a part of example ingestion job\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    ts = dt.now()\n",
    "    df = spark.range(row_count)\n",
    "    local_records = [\n",
    "        Row(\n",
    "            name=fake.name(),\n",
    "            address=fake.address(),\n",
    "            license_number=fake.license_plate(),\n",
    "            iban=fake.iban(),\n",
    "            bs=fake.bs(),\n",
    "            catch_phrase=fake.catch_phrase(),\n",
    "            company=fake.company(),\n",
    "            paragraph=fake.paragraph(nb_sentences=10),\n",
    "            created_at=fake.date_time(),\n",
    "            updated_at=ts\n",
    "        )\n",
    "        for i in range(row_count)\n",
    "    ]\n",
    "    df = spark.createDataFrame(local_records)\n",
    "    df = df.withColumn(\"uuid\", expr(\"uuid()\"))\n",
    "\n",
    "    print(f\"\"\"\n",
    "        dataframe of count {row_count} \n",
    "        was created from faker as {ts}\n",
    "    \"\"\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb5c509-bc62-4925-be6b-ddb97589016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(actor, io, table_name, action):\n",
    "    \"\"\" Get Location\n",
    "    <actors>/<table_name>/<action>/<timestamp>\n",
    "\n",
    "    :params actor: executor that called the function\n",
    "    :params io: intended SOURCE or SINK\n",
    "    :params table_name: name of that table that the location\n",
    "        is associated to\n",
    "    :params action: key event that caused the data creation\n",
    "    :return: Location\n",
    "    \"\"\"\n",
    "    ts_str = dt.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "    loc = f'{DATA_PATHS[actor][io]}/{table_name}/{action}/{ts_str}'\n",
    "    print(f'''\n",
    "        Location: {loc}\n",
    "            for {actor}\n",
    "            on {io} \n",
    "            for {table_name} \n",
    "            on {action}\n",
    "            at {ts_str}\n",
    "    ''')\n",
    "    return loc\n",
    "\n",
    "def extract_parquet(spark, loc):\n",
    "    \"\"\"Load data from Parquet file format.\n",
    "\n",
    "    :param spark: Spark session object.\n",
    "    :param loc: Location of data\n",
    "    :return: Spark DataFrame.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        spark\n",
    "        .read\n",
    "        .parquet(loc))\n",
    "    print(f\"\"\"\n",
    "        dataframe of count {df.count()} '\n",
    "        was read from location {loc}'\n",
    "    \"\"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_parquet(df, loc, num_of_output_files=1):\n",
    "    \"\"\"Load data to Parquet file format.\n",
    "\n",
    "    :param df: Spark Dataframe\n",
    "    :param loc: Location of data\n",
    "    :param num_of_output_files: number of files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    (df\n",
    "     .coalesce(num_of_output_files)\n",
    "     .write\n",
    "     .parquet(loc, mode='overwrite')\n",
    "     )\n",
    "\n",
    "    print(f'''\n",
    "        Successfully written {num_of_output_files} file\n",
    "        for on location {loc}\n",
    "    ''')\n",
    "\n",
    "\n",
    "def load_table(df, database_name, table_name):\n",
    "    \"\"\" Write a table in associated catalog\n",
    "\n",
    "    :params df: Dataframe to write\n",
    "    :params database_name: namespace as in catalog\n",
    "    :params table_name: table's name for reference\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    df.write.saveAsTable(f\"{database_name}.{table_name}\")\n",
    "    print(f' Successfully added table {database_name}.{table_name} to catalog ')\n",
    "\n",
    "def load_mock_db_initial_state(spark, df, table_name):\n",
    "    \"\"\" Write mock initial mock data for dimension table\n",
    "    This function creates mock initial load data that DMS would have\n",
    "    generated for a dimensional table that stores names of all entities\n",
    "    saved as Parquet files in tests/test_data. This will be used for\n",
    "    unit tests as well as to load as a part of example ingestion job.\n",
    "    :return: Location\n",
    "    \"\"\"\n",
    "\n",
    "    location = get_location(\n",
    "        actor='DMS',\n",
    "        io='SOURCE',\n",
    "        table_name=table_name,\n",
    "        action='initial_state'\n",
    "    )\n",
    "    load_parquet(\n",
    "        df=df,\n",
    "        loc=location\n",
    "    )\n",
    "\n",
    "    print(f'''\n",
    "        Successfully written Mock DB initial state\n",
    "        for table {table_name} on location {location}\n",
    "    ''')\n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6cfbcad-7985-464a-9934-b0a0064a5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mock_dms_full_load(table_name, df):\n",
    "    \"\"\" Mock AWS DMS full load\n",
    "    :param table_name: Source Table Name\n",
    "    :param df: Source Table Data\n",
    "    \"\"\"\n",
    "    df_initial_load = (\n",
    "        df\n",
    "        .withColumn(\n",
    "            \"Op\",\n",
    "            lit('I')\n",
    "        )\n",
    "        .withColumn(\n",
    "            'dms_export_timestamp',\n",
    "            current_timestamp()\n",
    "        )\n",
    "    )\n",
    "    location = get_location(\n",
    "        actor='DMS',\n",
    "        io='SINK',\n",
    "        table_name=table_name,\n",
    "        action='full_load'\n",
    "    )\n",
    "    load_parquet(\n",
    "        df=df_initial_load,\n",
    "        loc=location\n",
    "    )\n",
    "    print(f'''\n",
    "        Successfully written Mock DMS full initial load\n",
    "        for table {table_name} on location {location}\n",
    "    ''')\n",
    "\n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "631b60a2-da8e-4be7-8a99-9a1aedad9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mock_dms_cdc_load(table_name, df):\n",
    "    \"\"\" Mock AWS DMS full load\n",
    "    :param table_name: Source Table Name\n",
    "    :param df: Source Table Data\n",
    "    \"\"\"\n",
    "    df_initial_load = (\n",
    "        df\n",
    "        .withColumn(\n",
    "            \"Op\",\n",
    "            lit('U')\n",
    "        )\n",
    "        .withColumn(\n",
    "            'dms_export_timestamp',\n",
    "            current_timestamp()\n",
    "        )\n",
    "    )\n",
    "    location = get_location(\n",
    "        actor='DMS',\n",
    "        io='SINK',\n",
    "        table_name=table_name,\n",
    "        action='cdc_load'\n",
    "    )\n",
    "    load_parquet(\n",
    "        df=df_initial_load,\n",
    "        loc=location\n",
    "    )\n",
    "    print(f'''\n",
    "        Successfully written Mock DMS full initial load\n",
    "        for table {table_name} on location {location}\n",
    "    ''')\n",
    "\n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86354528-ea9a-4a10-855b-d1b66fbf84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        dataframe of count 1000 \n",
      "        was created from faker as 2024-06-29 13:35:54.350273\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df_dimension_table = create_mock_dimension_table_dataframe(\n",
    "    spark,\n",
    "    1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00bb9829-d668-4356-a546-878d8754512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " name           | Michael Hunt                                                                                                                                                                                                                                                                                                                                                    \n",
      " address        | 4258 Salazar Shoal\\nWest Adamchester, IN 52592                                                                                                                                                                                                                                                                                                                  \n",
      " license_number | 531GDH                                                                                                                                                                                                                                                                                                                                                          \n",
      " iban           | GB66PWWG56420154566070                                                                                                                                                                                                                                                                                                                                          \n",
      " bs             | transform back-end users                                                                                                                                                                                                                                                                                                                                        \n",
      " catch_phrase   | Pre-emptive well-modulated collaboration                                                                                                                                                                                                                                                                                                                        \n",
      " company        | Anderson LLC                                                                                                                                                                                                                                                                                                                                                    \n",
      " paragraph      | Admit American fall speak. Late hundred traditional summer tell season recently. Son your add project turn stuff anything score. Into help can bank public water. Able paper big. Positive politics offer often Democrat indicate stand. Management property out agreement. Fall price start language room see piece. Age which strategy federal rock stay yet. \n",
      " created_at     | 2012-07-02 18:58:45.737557                                                                                                                                                                                                                                                                                                                                      \n",
      " updated_at     | 2024-06-29 13:35:54.350273                                                                                                                                                                                                                                                                                                                                      \n",
      " uuid           | 16c52b8d-c856-412b-a603-df36ff792ffc                                                                                                                                                                                                                                                                                                                            \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dimension_table.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cfb7bd1-612a-4bc0-a302-38d1215a8cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Location: tests/test_data/db_data/demo/initial_state/2024_06_29-01:35:56_PM\n",
      "            for DMS\n",
      "            on SOURCE \n",
      "            for demo \n",
      "            on initial_state\n",
      "            at 2024_06_29-01:35:56_PM\n",
      "    \n",
      "\n",
      "        Successfully written 1 file\n",
      "        for on location tests/test_data/db_data/demo/initial_state/2024_06_29-01:35:56_PM\n",
      "    \n",
      "\n",
      "        Successfully written Mock DB initial state\n",
      "        for table demo on location tests/test_data/db_data/demo/initial_state/2024_06_29-01:35:56_PM\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "loc_db_initial_state = load_mock_db_initial_state(\n",
    "    spark,\n",
    "    df_dimension_table,\n",
    "    TABLES[1]['name']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1adb86d-f273-4ba3-8576-01ea3f4555e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        dataframe of count 1000 '\n",
      "        was read from location tests/test_data/db_data/demo/initial_state/2024_06_29-01:35:56_PM'\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df_mock_db_initial_state = extract_parquet(spark, loc_db_initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ec8f88c-446e-4a8f-8d96-826696848ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Location: tests/test_data/dms_sink/demo/full_load/2024_06_29-01:35:57_PM\n",
      "            for DMS\n",
      "            on SINK \n",
      "            for demo \n",
      "            on full_load\n",
      "            at 2024_06_29-01:35:57_PM\n",
      "    \n",
      "\n",
      "        Successfully written 1 file\n",
      "        for on location tests/test_data/dms_sink/demo/full_load/2024_06_29-01:35:57_PM\n",
      "    \n",
      "\n",
      "        Successfully written Mock DMS full initial load\n",
      "        for table demo on location tests/test_data/dms_sink/demo/full_load/2024_06_29-01:35:57_PM\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "loc_mock_dms_data = load_mock_dms_full_load(\n",
    "    TABLES[1]['name'],\n",
    "    df_mock_db_initial_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5237b575-1e1f-47ca-b9f7-cd26b546439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Location: tests/test_data/dms_sink/demo/cdc_load/2024_06_29-01:47:34_PM\n",
      "            for DMS\n",
      "            on SINK \n",
      "            for demo \n",
      "            on cdc_load\n",
      "            at 2024_06_29-01:47:34_PM\n",
      "    \n",
      "\n",
      "        Successfully written 1 file\n",
      "        for on location tests/test_data/dms_sink/demo/cdc_load/2024_06_29-01:47:34_PM\n",
      "    \n",
      "\n",
      "        Successfully written Mock DMS full initial load\n",
      "        for table demo on location tests/test_data/dms_sink/demo/cdc_load/2024_06_29-01:47:34_PM\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "loc_mock_dms_data = load_mock_dms_cdc_load(\n",
    "    TABLES[1]['name'],\n",
    "    df_mock_db_initial_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf45e31e-63a5-4da5-b25e-7bbfbc860a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        dataframe of count 1000 '\n",
      "        was read from location tests/test_data/dms_sink/demo/cdc_load/2024_06_29-01:47:34_PM'\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df_mock_dms_data = extract_parquet(spark, loc_mock_dms_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1805bff-4627-4a5d-bc2f-bb63de9c4133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.demo_single_big_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a62ef1a-7d11-4e72-abee-e58f3468ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mock_dms_data.writeTo(\"nyc.demo_single_big_file\").append()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3873c61-697c-4d22-9a81-594dcc2de6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count(1)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------+\n",
       "| count(1) |\n",
       "+----------+\n",
       "|     2000 |\n",
       "+----------+"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select count(*) from nyc.demo_single_big_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a8e490d-1604-43ed-ba80-b0f12d544563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count(1)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------+\n",
       "| count(1) |\n",
       "+----------+\n",
       "|     1000 |\n",
       "+----------+"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "WITH windowed_changes AS (\n",
    "    SELECT\n",
    "        op,\n",
    "        uuid,\n",
    "        updated_at,\n",
    "        row_number() OVER (\n",
    "            PARTITION BY uuid\n",
    "            ORDER BY updated_at DESC) AS row_num\n",
    "    FROM nyc.demo_single_big_file\n",
    "),\n",
    "mirror as (\n",
    "    SELECT uuid, updated_at, op\n",
    "    FROM windowed_changes WHERE row_num = 1 AND op != 'D'\n",
    ")\n",
    "select count(*) from mirror where op='U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843852b-0a46-40c6-881e-4401ebf01906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffd2c03",
   "metadata": {},
   "source": [
    "## Schema Evolution\n",
    "\n",
    "Adding, dropping, renaming, or altering columns is easy and safe in Iceberg. In this example, we'll rename `fare_amount` to `fare` and `trip_distance` to `distance`. We'll also add a float column `fare_per_distance_unit` immediately after `distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis RENAME COLUMN fare_amount TO fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis RENAME COLUMN trip_distance TO distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance COMMENT 'The elapsed trip distance in miles reported by the taximeter.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance TYPE double;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis ALTER COLUMN distance AFTER fare;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis\n",
    "ADD COLUMN fare_per_distance_unit float AFTER distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416b498",
   "metadata": {},
   "source": [
    "Let's update the new `fare_per_distance_unit` to equal `fare` divided by `distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18771ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "UPDATE nyc.taxis\n",
    "SET fare_per_distance_unit = fare/distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c72ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37582e02",
   "metadata": {},
   "source": [
    "## Expressive SQL for Row Level Changes\n",
    "With Iceberg tables, `DELETE` queries can be used to perform row-level deletes. This is as simple as providing the table name and a `WHERE` predicate. If the filter matches an entire partition of the table, Iceberg will intelligently perform a metadata-only operation where it simply deletes the metadata for that partition.\n",
    "\n",
    "Let's perform a row-level delete for all rows that have a `fare_per_distance_unit` greater than 4 or a `distance` greater than 2. This should leave us with relatively short trips that have a relatively high fare per distance traveled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded820f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.taxis\n",
    "WHERE fare_per_distance_unit > 4.0 OR distance > 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef3712",
   "metadata": {},
   "source": [
    "There are some fares that have a `null` for `fare_per_distance_unit` due to the distance being `0`. Let's remove those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b69265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.taxis\n",
    "WHERE fare_per_distance_unit is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b157e5",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "A table’s partitioning can be updated in place and applied only to newly written data. Query plans are then split, using the old partition scheme for data written before the partition scheme was changed, and using the new partition scheme for data written after. People querying the table don’t even have to be aware of this split. Simple predicates in WHERE clauses are automatically converted to partition filters that prune out files with no matches. This is what’s referred to in Iceberg as *Hidden Partitioning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.taxis\n",
    "ADD PARTITION FIELD VendorID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce6bb4",
   "metadata": {},
   "source": [
    "## Metadata Tables\n",
    "\n",
    "Iceberg tables contain very rich metadata that can be easily queried. For example, you can retrieve the manifest list for any snapshot, simply by querying the table's `snapshots` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fade1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT snapshot_id, manifest_list\n",
    "FROM nyc.taxis.snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64887133",
   "metadata": {},
   "source": [
    "The `files` table contains loads of information on data files, including column level statistics such as null counts, lower bounds, and upper bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb712f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT file_path, file_format, record_count, null_value_counts, lower_bounds, upper_bounds\n",
    "FROM nyc.taxis.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65deb074",
   "metadata": {},
   "source": [
    "## Time Travel\n",
    "\n",
    "The history table lists all snapshots and which parent snapshot they derive from. The `is_current_ancestor` flag let's you know if a snapshot is part of the linear history of the current snapshot of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab64f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47129d69",
   "metadata": {},
   "source": [
    "You can time-travel by altering the `current-snapshot-id` property of the table to reference any snapshot in the table's history. Let's revert the table to it's original state by traveling to the very first snapshot ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c360238",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --var df\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df43d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_snapshot = df.head().snapshot_id\n",
    "spark.sql(f\"CALL system.rollback_to_snapshot('nyc.taxis', {original_snapshot})\")\n",
    "original_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "VendorID\n",
    ",tpep_pickup_datetime\n",
    ",tpep_dropoff_datetime\n",
    ",fare\n",
    ",distance\n",
    ",fare_per_distance_unit\n",
    "FROM nyc.taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b71c76",
   "metadata": {},
   "source": [
    "Another look at the history table shows that the original state of the table has been added as a new entry\n",
    "with the original snapshot ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b801d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM nyc.taxis.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85667efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) as cnt\n",
    "FROM nyc.taxis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
